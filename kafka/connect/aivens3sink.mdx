---
title: Aiven Amazon S3 Sink Connector
---

Aiven Amazon S3 Sink Connector allows you to continuously store the data from
your Kafka Topics in Amazon S3. In this guide, we will walk you through creating
a Amazon S3 Sink Connector.

## Get Started

### Create a Kafka Cluster

<Info>
  If you do not have a Kafka cluster and/or topic already, follow [these
  steps](../overall/getstarted) to create one.
</Info>

### Prepare the Amazon S3 Environment

If you already have a Amazon S3 environment with the following information, skip
this step and continue from the [Create The Connector](#create-the-connector)
section. Note that the user with the given access keys, should have permission
to modify the given bucket.

- `aws.access.key.id`
- `aws.secret.access.key`
- `aws.s3.bucket.name`
- `aws.s3.region`

Go to [AWS S3 Console](https://s3.console.aws.amazon.com/s3/) Create or select a
bucket. Note that this bucket name will be used later to configure the
connector.

<Frame>
  <img src="/img/kafka/connect/aiven/amazonS3/01bucket.png" />
</Frame>

To make this guide simple, we will allow public access to this bucket(not
recomended in production).

<Frame>
  <img src="/img/kafka/connect/aiven/amazonS3/02bucket.png" />
</Frame>

You can disable public access and allow only following IP's coming from Upstash
:

```
52.48.149.7
52.213.40.91
174.129.75.41
34.195.190.47
52.58.175.235
18.158.44.120
63.34.151.162
54.247.137.96
3.78.151.126
3.124.80.204
34.236.200.33
44.195.74.73
```

Aside from bucket name and public access changes, default configurations should
be fine for this guide.

Next, we will create a user account with permissions to modify S3 buckets Go to
[AWS IAM](https://console.aws.amazon.com/iam) , then "Access Management" and
"Users". Click on "Add Users".

<Frame>
  <img src="/img/kafka/connect/aiven/amazonS3/03user.png" width="100%" />
</Frame>

Give a name to the user and continue with the next screen.

<Frame>
  <img src="/img/kafka/connect/aiven/amazonS3/04user.png" width="100%" />
</Frame>

On the "Set Permissions" screen, we will give the "AmazonFullS3Access" to this
user.

This gives more permissions than needed. You can create a custom policy with
following json for more restrictive policy.

```
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "VisualEditor0",
            "Effect": "Allow",
            "Action": [
                "s3:PutObject",
                "s3:GetObject",
                "s3:ListBucketMultipartUploads",
                "s3:AbortMultipartUpload",
                "s3:ListMultipartUploadParts"
            ],
            "Resource": "*"
        }
    ]
}
```

After creating the user, we will go into the details of that user to create a
key. Click on the user, then go to the "Security Credentials". An the "Access
Keys" section, click on the "Create access key" button.

<img src="/img/kafka/connect/aiven/amazonS3/06accesskey.png" width="100%" />

<Frame>
  <img src="/img/kafka/connect/aiven/amazonS3/07accesskey.png" width="100%" />
</Frame>

We will choose "Application running outside AWS" and create the access key.
Don't forget to store access key id and secret key. We will use these two when
creating the connector.

### Create the Connector

Go to the Connectors tab, and create your first connector by clicking the **New
Connector** button.

<Frame>
  <img src="/img/kafka/connect/connector.png" width="100%" />
</Frame>

Choose your connector as **Aiven Amazon S3 Connector**

<Frame>
  <img src="/img/kafka/connect/aiven/amazonS3/sink/1connector.png" />
</Frame>

Enter the required properties.

<Frame>
  <img src="/img/kafka/connect/aiven/amazonS3/sink/2config.png" />
</Frame>

The advanced screen is for any other configuration that the selected connector
supports. At the top of this screen, you can find a link to related
documentation. We can proceed with what we have and click the **Connect** button
directly.

<Frame>
  <img src="/img/kafka/connect/aiven/amazonS3/sink/3advanced.png" />
</Frame>

Congratulations! You have created an Aiven Amazon S3 Sink Connector.

As you put data into your selected topics, the data will be written into Amazon
S3. You can see the data coming from your related bucket in the Amazon Console.

<Frame>
  <img src="/img/kafka/connect/aiven/amazonS3/sink/4result.png" width="100%" />
</Frame>
